{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Quality and Validation in ETL**"
      ],
      "metadata": {
        "id": "zxnrtaOBAaSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : Define Data Quality in the context of ETL pipelines. Why is it more than just data\n",
        "cleaning?\n",
        "Ans: Data Quality in ETL refers to the accuracy, completeness, consistency, reliability, and\n",
        "validity of data as it moves through Extract, Transform, and Load processes.\n",
        "It is more than just data cleaning because:\n",
        "● Data cleaning only fixes errors (nulls, duplicates, wrong formats).\n",
        "● Data quality includes:\n",
        "○ Validation against business rules\n",
        "○ Referential integrity checks\n",
        "○ Consistency checks\n",
        "○ Accuracy verification\n",
        "○ Data profiling and monitoring\n",
        "\n",
        "So, data cleaning is only one part of overall data quality management.\n",
        "\n",
        "Question 2 : Explain why poor data quality leads to misleading dashboards and incorrect\n",
        "decisions.\n",
        "Ans: Poor data quality causes:\n",
        "1. Incorrect totals (due to duplicates)\n",
        "2. Wrong KPIs (due to null or missing values)\n",
        "3. Inflated revenue numbers\n",
        "4. Inaccurate customer counts\n",
        "5. Poor business decisions\n",
        "\n",
        "Example:\n",
        "If duplicate transactions exist, revenue will be counted multiple times → dashboard shows\n",
        "higher profit → management makes wrong strategic decisions.\n",
        "\n",
        "Question 3 : What is duplicate data? Explain three causes in ETL pipelines. ans:Duplicate\n",
        "data means repeated records representing the same real-world transaction.\n",
        "Causes:\n",
        "1. Multiple Loads\n",
        "○ Same file loaded twice.\n",
        "2. Missing Primary Key Constraints\n",
        "○ No uniqueness check on business keys.\n",
        "3. System Integration Issues\n",
        "○ Data coming from multiple sources without deduplication logic.\n",
        "\n",
        "Question 4 : Differentiate between exact, partial, and fuzzy duplicates.\n",
        "Ans:\n",
        "Type Meaning Example\n",
        "Exact Duplicate All fields identical Same transaction repeated\n",
        "\n",
        "Partial\n",
        "Duplicate\n",
        "\n",
        "Some fields same, some\n",
        "different\n",
        "\n",
        "Same Customer_ID + Product_ID but\n",
        "different city\n",
        "\n",
        "Fuzzy\n",
        "Duplicate\n",
        "\n",
        "Similar but not exact \"Rahul Mehta\" vs \"Rahul M.\"\n",
        "\n",
        "Question 5 : Why should data validation be performed during transformation rather than after\n",
        "loading?\n",
        "\n",
        "Ans: Validation should be done during transformation because:\n",
        "\n",
        "● Errors are caught before loading to warehouse.\n",
        "● Prevents corrupted data from entering reporting systems.\n",
        "● Saves reprocessing time.\n",
        "● Maintains integrity before storage.\n",
        "\n",
        "If validation is done after loading, wrong data may already affect dashboards.\n",
        "Question 6 : Explain how business rules help in validating data accuracy. Give an example.\n",
        "Ans: Business rules define acceptable values.\n",
        "Example rules:\n",
        "● Quantity must be > 0\n",
        "● Txn_Amount cannot be NULL\n",
        "● Txn_Date cannot be future date\n",
        "● Customer_ID must exist in master table\n",
        "\n",
        "Example:\n",
        "If Quantity = NULL (like C104 record), rule rejects or flags it.\n",
        "Business rules ensure data accuracy and reliability.\n",
        "\n",
        "Question 7 : Write an SQL query on to list all duplicate keys and their counts using the business\n",
        "key (Customer_ID + Product_ID + Txn_Date + Txn_Amount ).\n",
        "Ans: Business Key:\n",
        "(Customer_ID + Product_ID + Txn_Date + Txn_Amount)\n",
        "SELECT\n",
        "Customer_ID,\n",
        "Product_ID,\n",
        "Txn_Date,\n",
        "Txn_Amount,\n",
        "COUNT(*) AS duplicate_count\n",
        "\n",
        "FROM Sales_Transactions\n",
        "GROUP BY\n",
        "Customer_ID,\n",
        "Product_ID,\n",
        "Txn_Date,\n",
        "Txn_Amount\n",
        "HAVING COUNT(*) > 1;\n",
        "\n",
        "Question 8 : Enforcing Referential Integrity Assume:\n",
        "Ans:Customers_Master contains:\n",
        "C101\n",
        "C102\n",
        "C103\n",
        "C104\n",
        "But Sales_Transactions contains:\n",
        "C105 ❌\n",
        "C106 ❌\n",
        "These violate referential integrity.\n",
        "SELECT DISTINCT s.Customer_ID\n",
        "FROM Sales_Transactions s\n",
        "LEFT JOIN Customers_Master c\n",
        "ON s.Customer_ID = c.CustomerID\n",
        "WHERE c.CustomerID IS NULL;\n",
        "Output:\n",
        "C105\n",
        "C106\n",
        "These customer IDs do not exist in Customers_Master."
      ],
      "metadata": {
        "id": "YWyeHwqDAae7"
      }
    }
  ]
}